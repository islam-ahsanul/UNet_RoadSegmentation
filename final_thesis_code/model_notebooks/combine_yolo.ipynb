{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/home/ahsan/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeding for reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Hyperparameters\n",
    "height = 512\n",
    "width = 768\n",
    "num_classes = 3\n",
    "\n",
    "# Paths\n",
    "dataset_path = \"/home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test\"\n",
    "save_path = \"/home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/combined_result\"\n",
    "yolo_model_path = \"/home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/files/aug/best.pt\"\n",
    "unet_model_path = \"/home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/files/aug/unet-multiclass.keras\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Save Directory\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLO Model\n",
    "yolo_model = YOLO(yolo_model_path)\n",
    "\n",
    "# Load U-Net Model\n",
    "unet_model = tf.keras.models.load_model(unet_model_path, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test images\n",
    "test_x = sorted(glob(os.path.join(dataset_path, \"images\", \"*.png\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   0%|          | 0/19 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0008.png: 448x640 (no detections), 139.0ms\n",
      "Speed: 3.1ms preprocess, 139.0ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:   5%|▌         | 1/19 [00:02<00:51,  2.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0010.png: 448x640 1 person, 84.3ms\n",
      "Speed: 15.3ms preprocess, 84.3ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  11%|█         | 2/19 [00:03<00:28,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0014.png: 448x640 (no detections), 85.7ms\n",
      "Speed: 0.8ms preprocess, 85.7ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  16%|█▌        | 3/19 [00:04<00:21,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0016.png: 448x640 (no detections), 91.0ms\n",
      "Speed: 15.8ms preprocess, 91.0ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 739ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  21%|██        | 4/19 [00:05<00:17,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0035.png: 448x640 (no detections), 83.6ms\n",
      "Speed: 0.8ms preprocess, 83.6ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 756ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  26%|██▋       | 5/19 [00:06<00:14,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0039.png: 448x640 (no detections), 82.3ms\n",
      "Speed: 15.7ms preprocess, 82.3ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 723ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  32%|███▏      | 6/19 [00:07<00:12,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0040.png: 448x640 (no detections), 83.6ms\n",
      "Speed: 0.9ms preprocess, 83.6ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 730ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  37%|███▋      | 7/19 [00:08<00:11,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0050.png: 448x640 1 person, 1 bicycle, 103.5ms\n",
      "Speed: 17.6ms preprocess, 103.5ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 740ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  42%|████▏     | 8/19 [00:09<00:10,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0057.png: 448x640 (no detections), 102.0ms\n",
      "Speed: 0.9ms preprocess, 102.0ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  47%|████▋     | 9/19 [00:09<00:09,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0060.png: 448x640 1 person, 1 rickshaw van, 92.5ms\n",
      "Speed: 0.8ms preprocess, 92.5ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 729ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  53%|█████▎    | 10/19 [00:11<00:09,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0062.png: 448x640 1 person, 1 motorcycle, 87.0ms\n",
      "Speed: 16.0ms preprocess, 87.0ms inference, 0.4ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 728ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  58%|█████▊    | 11/19 [00:12<00:08,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0074.png: 448x640 (no detections), 106.8ms\n",
      "Speed: 0.8ms preprocess, 106.8ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 721ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  63%|██████▎   | 12/19 [00:13<00:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0083.png: 448x640 (no detections), 84.4ms\n",
      "Speed: 15.4ms preprocess, 84.4ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 738ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  68%|██████▊   | 13/19 [00:14<00:06,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0084.png: 448x640 1 person, 1 motorcycle, 88.2ms\n",
      "Speed: 15.5ms preprocess, 88.2ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 725ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  74%|███████▎  | 14/19 [00:15<00:05,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0093.png: 448x640 1 auto rickshaw, 1 private car, 90.6ms\n",
      "Speed: 0.9ms preprocess, 90.6ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 735ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  79%|███████▉  | 15/19 [00:16<00:03,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0099.png: 448x640 1 rickshaw van, 92.1ms\n",
      "Speed: 19.5ms preprocess, 92.1ms inference, 0.3ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 737ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  84%|████████▍ | 16/19 [00:17<00:02,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0104.png: 448x640 (no detections), 114.2ms\n",
      "Speed: 0.9ms preprocess, 114.2ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 743ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  89%|████████▉ | 17/19 [00:18<00:01,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0109.png: 448x640 (no detections), 86.3ms\n",
      "Speed: 0.8ms preprocess, 86.3ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 733ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images:  95%|█████████▍| 18/19 [00:19<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/ahsan/University/Thesis/UNet_Directory/Datasets/second_phase/processed_dataset/aug/test/images/0115.png: 448x640 (no detections), 92.1ms\n",
      "Speed: 15.4ms preprocess, 92.1ms inference, 0.2ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 726ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Images: 100%|██████████| 19/19 [00:19<00:00,  1.05s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Mapping grayscale values to class labels for segmentation mask\n",
    "class_colors = {\n",
    "    0: (0, 0, 0),       # Non-Drivable Area (black)\n",
    "    1: (79, 247, 211),  # My Way (Greenish-Yellow)\n",
    "    2: (247, 93, 79)    # Other Way (Red)\n",
    "}\n",
    "\n",
    "# Track inference times\n",
    "time_taken = []\n",
    "\n",
    "for x_path in tqdm(test_x, desc=\"Processing Images\"):\n",
    "    name = os.path.basename(x_path)\n",
    "    original_img = cv2.imread(x_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    if original_img is None:\n",
    "        print(f\"Error loading image {x_path}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Resize image for model input\n",
    "    resized_img = cv2.resize(original_img, (width, height))\n",
    "    img_input = resized_img / 255.0\n",
    "    img_input = np.expand_dims(img_input, axis=0)\n",
    "\n",
    "    ####### 1. YOLO Object Detection #######\n",
    "    yolo_results = yolo_model(x_path)[0]\n",
    "    yolo_output = original_img.copy()\n",
    "\n",
    "    for result in yolo_results.boxes:\n",
    "        x1, y1, x2, y2 = map(int, result.xyxy[0].tolist())  # Bounding box coordinates\n",
    "        confidence = result.conf[0].item()\n",
    "        label = int(result.cls[0].item())\n",
    "\n",
    "        # Draw bounding boxes\n",
    "        cv2.rectangle(yolo_output, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(yolo_output, f\"Class {label}: {confidence:.2f}\", \n",
    "                    (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Save YOLO output image\n",
    "    yolo_save_path = os.path.join(save_path, f\"{name.split('.')[0]}_yolo.png\")\n",
    "    cv2.imwrite(yolo_save_path, yolo_output)\n",
    "\n",
    "    ####### 2. U-Net Road Segmentation #######\n",
    "    start_time = time.time()\n",
    "    unet_prediction = unet_model.predict(img_input)[0]\n",
    "    time_taken.append(time.time() - start_time)\n",
    "\n",
    "    # Convert model output to mask\n",
    "    predicted_mask = np.argmax(unet_prediction, axis=-1).astype(np.uint8)\n",
    "\n",
    "    # Convert mask to color format\n",
    "    seg_colored = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for label, color in class_colors.items():\n",
    "        seg_colored[predicted_mask == label] = color\n",
    "\n",
    "    # Save segmentation mask\n",
    "    seg_save_path = os.path.join(save_path, f\"{name.split('.')[0]}_segmentation.png\")\n",
    "    cv2.imwrite(seg_save_path, seg_colored)\n",
    "\n",
    "    ####### 3. Combined Image (YOLO + Segmentation) #######\n",
    "    combined_output = cv2.addWeighted(yolo_output, 0.6, seg_colored, 0.4, 0)\n",
    "\n",
    "    # Save combined output\n",
    "    combined_save_path = os.path.join(save_path, f\"{name.split('.')[0]}_combined.png\")\n",
    "    cv2.imwrite(combined_save_path, combined_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FPS Calculation\n",
    "mean_time = np.mean(time_taken)\n",
    "mean_fps = 1 / mean_time\n",
    "print(f\"Mean time taken per image: {mean_time:.4f} seconds\")\n",
    "print(f\"Mean FPS: {mean_fps:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
